\section{Text Embedding}
Text embedding techniques are improved for specific objectives, fields and styles and applied to a wide range of tasks, including various issues of tweets analysis[Mottaghinia et al., 2020], visualisation in the biomedical field [Oubenali et al., 2022] and sentiment analysis on movie reviews [Sivakumar et al., 2021].

[Khatua et al., 2019] identified crisis-related tweets during the 2014 Ebola and 2016 Zika outbreaks with pre-trained Word2Vec and GloVe models.
They found a better classification performance to have a small domain-specific corpus from tweets and scholarly abstracts from PubMed participated in the model.
They also observed a higher accuracy from a higher dimension of word vector and skip-gram model than CBOW.

[Lee et al., 2018] utilized SentiWordNet 3.0 to analyse the effect of several negative emotions in hotel reviews.
SentiWordNet 3.0 [Baccianella et al., 2010] provided sentiment analysis as classification tasks and word embedding with a frequency-weighted bag-of-words model and the help of WordNet corpus.

[Onan, 2020] presented a sentiment analysis approach to product reviews from Twitter.
This deep-learning-based method applied TF-IDF weighted GloVe to the CNN-LSTM architecture to do word embedding and outperformed conventional deep-learning methods.

\section{Text Embedding for Search Engine}
With the increase of documents and web pages, traditional keywords-based search engines are thought to be powerless to correctly look for users' requirements.
Text embedding techniques are applied to search engines to provide machine-readable web pages and semantic annotations to the algorithm to yield a more accurate search result[Aghaei et al., 2022].

[Azad et al., 2022] proposed a semantic search over linked data